{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372be3c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 聚类分析笔记本\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 导入自定义模块\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.data.preprocessor import DataPreprocessor\n",
    "from src.models.cluster_analyzer import ClusterAnalyzer\n",
    "from src.models.pca_analyzer import PCAAnalyzer\n",
    "from src.visualization.plot_utils import VisualizationUtils\n",
    "\n",
    "# 1. 数据准备\n",
    "print(\"=== 聚类分析 ===\")\n",
    "\n",
    "# 加载数据\n",
    "loader = DataLoader()\n",
    "panel_data = loader.load_panel_data()\n",
    "\n",
    "# 使用2023年数据\n",
    "data_2023 = panel_data[panel_data['年份'] == 2023].copy()\n",
    "\n",
    "# 选择聚类变量\n",
    "cluster_vars = [\n",
    "    '跨境数据传输总量_TB',\n",
    "    '数据中心数量',\n",
    "    '互联网国际出口带宽_Gbps',\n",
    "    'GDP_亿元',\n",
    "    '数字经济核心产业增加值_亿元',\n",
    "    '研发经费投入_亿元',\n",
    "    '5G基站数量',\n",
    "    '算力规模_PFLOPS'\n",
    "]\n",
    "\n",
    "# 检查变量是否存在\n",
    "existing_vars = [var for var in cluster_vars if var in data_2023.columns]\n",
    "print(f\"使用的聚类变量: {len(existing_vars)}个\")\n",
    "\n",
    "# 提取数据\n",
    "X_raw = data_2023[existing_vars].values\n",
    "city_labels = data_2023['城市'].values\n",
    "city_codes = data_2023['city_code'].values\n",
    "\n",
    "print(f\"数据形状: {X_raw.shape}\")\n",
    "print(f\"城市数量: {len(city_labels)}\")\n",
    "\n",
    "# 2. 数据预处理\n",
    "print(\"\\n=== 数据预处理 ===\")\n",
    "preprocessor = DataPreprocessor(method='median', scale_method='standard')\n",
    "\n",
    "# 处理缺失值\n",
    "X_clean = preprocessor.handle_missing_values(pd.DataFrame(X_raw, columns=existing_vars))\n",
    "\n",
    "# 处理异常值\n",
    "X_no_outliers = preprocessor.handle_outliers(X_clean, method='cap')\n",
    "\n",
    "# 标准化\n",
    "X_scaled = preprocessor.scale_data(X_no_outliers)\n",
    "\n",
    "print(\"预处理完成!\")\n",
    "\n",
    "# 3. 聚类分析\n",
    "print(\"\\n=== 聚类分析 ===\")\n",
    "cluster_analyzer = ClusterAnalyzer(random_state=42)\n",
    "\n",
    "# 3.1 确定最优聚类数量\n",
    "print(\"\\n1. 确定最优聚类数量...\")\n",
    "\n",
    "# 使用K-means方法确定最优聚类数\n",
    "kmeans_scores = cluster_analyzer.determine_optimal_clusters(\n",
    "    X_scaled.values, \n",
    "    method='kmeans',\n",
    "    max_clusters=min(8, len(city_labels))\n",
    ")\n",
    "\n",
    "print(\"K-means聚类评估:\")\n",
    "for i in range(len(kmeans_scores['n_clusters'])):\n",
    "    print(f\"  聚类数={kmeans_scores['n_clusters'][i]:2d}: \"\n",
    "          f\"轮廓系数={kmeans_scores['silhouette'][i]:.3f}, \"\n",
    "          f\"CH指数={kmeans_scores['calinski_harabasz'][i]:.1f}\")\n",
    "\n",
    "# 选择轮廓系数最大的聚类数\n",
    "best_k_index = np.argmax(kmeans_scores['silhouette'])\n",
    "optimal_n_clusters = kmeans_scores['n_clusters'][best_k_index]\n",
    "print(f\"\\n最优聚类数量: {optimal_n_clusters}\")\n",
    "\n",
    "# 3.2 可视化聚类评估\n",
    "print(\"\\n2. 可视化聚类评估...\")\n",
    "cluster_analyzer.plot_cluster_evaluation(\n",
    "    kmeans_scores, \n",
    "    method='kmeans',\n",
    "    save_path='../outputs/figures/cluster_evaluation.png'\n",
    ")\n",
    "\n",
    "# 4. 应用不同聚类算法\n",
    "print(\"\\n=== 应用不同聚类算法 ===\")\n",
    "\n",
    "clustering_results = {}\n",
    "methods = ['kmeans', 'hierarchical', 'gmm']\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"\\n应用{method}聚类...\")\n",
    "    \n",
    "    if method == 'kmeans':\n",
    "        labels = cluster_analyzer.fit_clustering(\n",
    "            X_scaled.values,\n",
    "            method='kmeans',\n",
    "            n_clusters=optimal_n_clusters\n",
    "        )\n",
    "    elif method == 'hierarchical':\n",
    "        labels = cluster_analyzer.fit_clustering(\n",
    "            X_scaled.values,\n",
    "            method='hierarchical',\n",
    "            n_clusters=optimal_n_clusters\n",
    "        )\n",
    "    elif method == 'gmm':\n",
    "        labels = cluster_analyzer.fit_clustering(\n",
    "            X_scaled.values,\n",
    "            method='gmm',\n",
    "            n_clusters=optimal_n_clusters\n",
    "        )\n",
    "    \n",
    "    clustering_results[method] = labels\n",
    "    \n",
    "    # 计算聚类质量\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        silhouette = cluster_analyzer.scores.get('silhouette', 0)\n",
    "        print(f\"  轮廓系数: {silhouette:.3f}\")\n",
    "        \n",
    "        # 显示每个聚类的城市\n",
    "        print(f\"  聚类分布:\")\n",
    "        unique_labels = np.unique(labels)\n",
    "        for label in unique_labels:\n",
    "            if label != -1:  # 跳过噪声点\n",
    "                cluster_cities = city_labels[labels == label]\n",
    "                print(f\"    聚类{label}: {len(cluster_cities)}个城市 - {', '.join(cluster_cities)}\")\n",
    "\n",
    "# 5. 选择最佳聚类结果\n",
    "print(\"\\n=== 选择最佳聚类结果 ===\")\n",
    "best_method = None\n",
    "best_score = -1\n",
    "\n",
    "for method, labels in clustering_results.items():\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        score = silhouette_score(X_scaled.values, labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_method = method\n",
    "\n",
    "print(f\"最佳聚类方法: {best_method} (轮廓系数: {best_score:.3f})\")\n",
    "best_labels = clustering_results[best_method]\n",
    "\n",
    "# 6. 聚类结果可视化\n",
    "print(\"\\n=== 聚类结果可视化 ===\")\n",
    "\n",
    "# 6.1 使用PCA降维可视化\n",
    "print(\"1. PCA降维可视化...\")\n",
    "pca_visualizer = PCAAnalyzer(n_components=2)\n",
    "pca_visualizer.fit(X_scaled.values, feature_names=existing_vars)\n",
    "X_pca = pca_visualizer.transform(X_scaled.values)\n",
    "\n",
    "# 绘制聚类散点图\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "unique_labels = np.unique(best_labels)\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    if label == -1:  # 噪声点\n",
    "        color = 'gray'\n",
    "        label_name = '噪声'\n",
    "    else:\n",
    "        label_name = f'聚类{label}'\n",
    "    \n",
    "    mask = best_labels == label\n",
    "    ax.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
    "              c=[color], label=label_name,\n",
    "              alpha=0.8, s=150, edgecolors='k')\n",
    "    \n",
    "    # 添加城市标签\n",
    "    for i, city in enumerate(city_labels[mask]):\n",
    "        ax.annotate(city, (X_pca[mask, 0][i], X_pca[mask, 1][i]),\n",
    "                   xytext=(5, 5), textcoords='offset points',\n",
    "                   fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('PC1', fontsize=12)\n",
    "ax.set_ylabel('PC2', fontsize=12)\n",
    "ax.set_title(f'{best_method}聚类结果可视化 (PCA降维)', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/cluster_pca_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 6.2 绘制层次聚类树状图\n",
    "print(\"2. 层次聚类树状图...\")\n",
    "if 'hierarchical' in clustering_results:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # 计算链接矩阵\n",
    "    linkage_matrix = linkage(X_scaled.values, method='ward')\n",
    "    \n",
    "    # 绘制树状图\n",
    "    dendrogram(linkage_matrix, labels=city_labels, ax=ax,\n",
    "              leaf_rotation=90, leaf_font_size=10)\n",
    "    \n",
    "    ax.set_xlabel('城市', fontsize=12)\n",
    "    ax.set_ylabel('距离', fontsize=12)\n",
    "    ax.set_title('层次聚类树状图', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../outputs/figures/hierarchical_dendrogram.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 6.3 聚类特征分析\n",
    "print(\"3. 聚类特征分析...\")\n",
    "cluster_stats = cluster_analyzer.analyze_cluster_characteristics(\n",
    "    pd.DataFrame(X_scaled, columns=existing_vars),\n",
    "    best_labels\n",
    ")\n",
    "\n",
    "print(\"\\n聚类特征统计:\")\n",
    "print(cluster_stats.to_string(index=False))\n",
    "\n",
    "# 7. 聚类结果综合展示\n",
    "print(\"\\n=== 聚类结果综合展示 ===\")\n",
    "\n",
    "# 创建聚类结果DataFrame\n",
    "cluster_results_df = pd.DataFrame({\n",
    "    '城市': city_labels,\n",
    "    '城市代码': city_codes,\n",
    "    '聚类标签': best_labels\n",
    "})\n",
    "\n",
    "# 添加原始特征值\n",
    "for i, var in enumerate(existing_vars):\n",
    "    cluster_results_df[var] = X_raw[:, i]\n",
    "\n",
    "print(\"\\n聚类结果:\")\n",
    "print(cluster_results_df[['城市', '聚类标签'] + existing_vars[:3]].to_string(index=False))\n",
    "\n",
    "# 8. 聚类特征雷达图\n",
    "print(\"\\n=== 聚类特征雷达图 ===\")\n",
    "\n",
    "if cluster_analyzer.cluster_centers is not None:\n",
    "    n_clusters = len(np.unique(best_labels[best_labels != -1]))\n",
    "    n_features = min(6, len(existing_vars))\n",
    "    \n",
    "    # 选择关键特征\n",
    "    selected_features = existing_vars[:n_features]\n",
    "    \n",
    "    # 计算每个聚类的特征均值（标准化前）\n",
    "    cluster_means_original = []\n",
    "    for label in np.unique(best_labels):\n",
    "        if label != -1:  # 跳过噪声点\n",
    "            mask = best_labels == label\n",
    "            cluster_means = X_raw[mask][:, :n_features].mean(axis=0)\n",
    "            cluster_means_original.append(cluster_means)\n",
    "    \n",
    "    if cluster_means_original:\n",
    "        cluster_means_original = np.array(cluster_means_original)\n",
    "        \n",
    "        # 创建雷达图\n",
    "        fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection='polar'))\n",
    "        \n",
    "        angles = np.linspace(0, 2*np.pi, n_features, endpoint=False).tolist()\n",
    "        angles += angles[:1]  # 闭合图形\n",
    "        \n",
    "        for i, means in enumerate(cluster_means_original):\n",
    "            # 归一化到0-1范围用于雷达图显示\n",
    "            normalized_means = (means - means.min()) / (means.max() - means.min() + 1e-8)\n",
    "            values = normalized_means.tolist()\n",
    "            values += values[:1]\n",
    "            \n",
    "            ax.plot(angles, values, 'o-', linewidth=2, label=f'聚类{i}', markersize=8)\n",
    "            ax.fill(angles, values, alpha=0.1)\n",
    "        \n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(selected_features)\n",
    "        ax.set_title('聚类特征雷达图（原始值）', fontsize=14, fontweight='bold', pad=20)\n",
    "        ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "        ax.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../outputs/figures/cluster_radar_chart.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# 9. 聚类演化分析（跨年度）\n",
    "print(\"\\n=== 聚类演化分析 ===\")\n",
    "\n",
    "# 分析各年度聚类变化\n",
    "years = sorted(panel_data['年份'].unique())\n",
    "yearly_clusters = {}\n",
    "\n",
    "for year in years:\n",
    "    year_data = panel_data[panel_data['年份'] == year]\n",
    "    \n",
    "    if len(year_data) < 5:  # 数据太少跳过\n",
    "        continue\n",
    "    \n",
    "    # 提取数据\n",
    "    X_year = year_data[existing_vars].values\n",
    "    city_labels_year = year_data['城市'].values\n",
    "    \n",
    "    # 预处理\n",
    "    X_year_clean = preprocessor.handle_missing_values(\n",
    "        pd.DataFrame(X_year, columns=existing_vars)\n",
    "    )\n",
    "    X_year_scaled = preprocessor.scale_data(X_year_clean)\n",
    "    \n",
    "    # 聚类\n",
    "    labels_year = cluster_analyzer.fit_clustering(\n",
    "        X_year_scaled.values,\n",
    "        method=best_method,\n",
    "        n_clusters=optimal_n_clusters\n",
    "    )\n",
    "    \n",
    "    yearly_clusters[year] = dict(zip(city_labels_year, labels_year))\n",
    "\n",
    "print(f\"分析了 {len(yearly_clusters)} 个年度的聚类\")\n",
    "\n",
    "# 10. 保存结果\n",
    "print(\"\\n=== 保存结果 ===\")\n",
    "\n",
    "# 保存聚类结果\n",
    "cluster_results_df.to_csv('../outputs/tables/clustering_results.csv', index=False)\n",
    "print(\"聚类结果已保存至: ../outputs/tables/clustering_results.csv\")\n",
    "\n",
    "# 保存聚类统计\n",
    "cluster_stats.to_csv('../outputs/tables/cluster_statistics.csv', index=False)\n",
    "print(\"聚类统计已保存至: ../outputs/tables/cluster_statistics.csv\")\n",
    "\n",
    "# 保存年度聚类结果\n",
    "yearly_clusters_df = pd.DataFrame(yearly_clusters)\n",
    "yearly_clusters_df.to_csv('../outputs/tables/yearly_clusters.csv')\n",
    "print(\"年度聚类结果已保存至: ../outputs/tables/yearly_clusters.csv\")\n",
    "\n",
    "# 保存评估分数\n",
    "kmeans_scores_df = pd.DataFrame(kmeans_scores)\n",
    "kmeans_scores_df.to_csv('../outputs/tables/cluster_evaluation_scores.csv', index=False)\n",
    "print(\"聚类评估分数已保存至: ../outputs/tables/cluster_evaluation_scores.csv\")\n",
    "\n",
    "print(\"\\n=== 聚类分析完成 ===\")\n",
    "print(f\"生成图表数量: 4张\")\n",
    "print(f\"生成表格数量: 4个\")\n",
    "print(f\"最优聚类方法: {best_method}\")\n",
    "print(f\"最优聚类数量: {optimal_n_clusters}\")\n",
    "print(f\"最佳轮廓系数: {best_score:.3f}\")\n",
    "print(f\"所有输出已保存至 ../outputs/ 目录\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
